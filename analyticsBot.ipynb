{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ6pkUQNGzSNkoplbNUz0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youssefsalah224/analytics-Bot/blob/main/analyticsBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-analytics-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US6JsmkMjiIV",
        "outputId": "f366d65b-605f-4dc0-a78d-5f4f8257d06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/153.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/153.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from google.analytics.data_v1beta import BetaAnalyticsDataClient\n",
        "from google.analytics.data_v1beta.types import (\n",
        "    DateRange,\n",
        "    Dimension,\n",
        "    Metric,\n",
        "    MetricType,\n",
        "    RunReportRequest,\n",
        ")\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "id": "KGiStq1hcgpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352e29a7-c7fc-4177-fa6f-7cb9bafd99bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "id": "8VuFUZSZjB7X",
        "outputId": "39f82916-24f6-49ec-871c-2cad19af55ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter your quieres     (u need to inter the matrix right)   fitch the totalUsers and the browser\n",
            "totalUsers\n",
            "2 analytics rows found\n",
            "Dimension header name: browser\n",
            "Metric header name: totalUsers (TYPE_INTEGER)\n",
            "Report result:\n",
            "\n",
            "Row 0\n",
            "browser: Chrome\n",
            "totalUsers: 10\n",
            "      0\n",
            "0  10.0\n",
            "1   4.0\n",
            "dimension_headers {\n",
            "  name: \"browser\"\n",
            "}\n",
            "metric_headers {\n",
            "  name: \"totalUsers\"\n",
            "  type_: TYPE_INTEGER\n",
            "}\n",
            "rows {\n",
            "  dimension_values {\n",
            "    value: \"Chrome\"\n",
            "  }\n",
            "  metric_values {\n",
            "    value: \"10\"\n",
            "  }\n",
            "}\n",
            "rows {\n",
            "  dimension_values {\n",
            "    value: \"Safari\"\n",
            "  }\n",
            "  metric_values {\n",
            "    value: \"4\"\n",
            "  }\n",
            "}\n",
            "row_count: 2\n",
            "metadata {\n",
            "  currency_code: \"EGP\"\n",
            "  time_zone: \"Africa/Cairo\"\n",
            "}\n",
            "kind: \"analyticsData#runReport\"\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'json_object = json.dumps(data, indent=4)\\n\\n# Writing to sample.json\\nwith open(\"sample.json\", \"w\") as outfile:\\n\\toutfile.write(data)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'service_key.json'\n",
        "\n",
        "\n",
        "def extract_metrics(input_text):\n",
        "    words = nltk.word_tokenize(input_text)\n",
        "    metric_mapping = {\n",
        "        \"addToCarts\",\n",
        "        \"sessions\",\n",
        "        \"totalUsers\",\n",
        "        \"totalUsers\",\n",
        "        \"itemsPurchased\",\n",
        "        \"totalAdRevenue\"\n",
        "    }\n",
        "    for word in words:\n",
        "      if word in metric_mapping:\n",
        "        matrics=word\n",
        "        print(matrics)\n",
        "    return matrics\n",
        "\n",
        "def extract_dimencions(input_text):\n",
        "\n",
        "    words = nltk.word_tokenize(input_text)\n",
        "    dimencion_mapping = {\n",
        "        \"achievementId\",\n",
        "        \"adFormat\",\n",
        "        \"adSourceName\",\n",
        "        \"adUnitName\",\n",
        "        \"browser\"\n",
        "    }\n",
        "    for word in words:\n",
        "      if word in dimencion_mapping:\n",
        "        my_dimencion=word\n",
        "    return my_dimencion\n",
        "\n",
        "\n",
        "\n",
        "def run_report(property_id,extracted_matrixs,extracted_dimencion):\n",
        "    \"\"\"        Runs a report by the client call       \"\"\"\n",
        "    client = BetaAnalyticsDataClient()\n",
        "\n",
        "    request = RunReportRequest(\n",
        "        property=f\"properties/{property_id}\",\n",
        "        dimensions=[Dimension(name=extracted_dimencion)],\n",
        "        metrics=[Metric(name=extracted_matrixs)],\n",
        "        date_ranges=[DateRange(start_date=\"1000daysAgo\",end_date=\"today\")],\n",
        "    )\n",
        "\n",
        "    response = client.run_report(request)\n",
        "    print_run_report_response(response)\n",
        "    print(response)\n",
        "\n",
        "\n",
        "def print_run_report_response(response):\n",
        "    #Prints results of a runReport call.\n",
        "    print(f\"{response.row_count} analytics rows found\")\n",
        "    for dimensionHeader in response.dimension_headers:\n",
        "        print(f\"Dimension header name: {dimensionHeader.name}\")\n",
        "\n",
        "    for metricHeader in response.metric_headers:\n",
        "        metric_type = MetricType(metricHeader.type_).name\n",
        "        print(f\"Metric header name: {metricHeader.name} ({metric_type})\")\n",
        "\n",
        "\n",
        "    row_index_names = [header.name for header in response.dimension_headers]\n",
        "    row_header = []\n",
        "    for i in range(len(row_index_names)):\n",
        "        row_header.append([row.dimension_values[i].value for row in response.rows])\n",
        "\n",
        "    row_index_named = pd.MultiIndex.from_arrays(np.array(row_header), names = np.array(row_index_names))\n",
        "    print(\"Report result:\")\n",
        "    for rowIdx, row in enumerate(response.rows):\n",
        "        print(f\"\\nRow {rowIdx}\")\n",
        "        data_values=[]\n",
        "        row_header = []\n",
        "        for i, dimension_value in enumerate(row.dimension_values):\n",
        "            row_header.append([row.dimension_values[i].value for row in response.rows])\n",
        "            dimension_name = response.dimension_headers[i].name\n",
        "            print(f\"{dimension_name}: {dimension_value.value}\")\n",
        "\n",
        "        for i, metric_value in enumerate(row.metric_values):\n",
        "            metric_name = response.metric_headers[i].name\n",
        "            data_values.append([row.metric_values[i].value for row in response.rows])\n",
        "            print(f\"{metric_name}: {metric_value.value}\")\n",
        "        output = pd.DataFrame(data = np.transpose(np.array(data_values, dtype = 'f'))  )\n",
        "        print(output)\n",
        "        return output\n",
        "        output.reset_index().to_excel('GA4_python_output.xlsx', sheet_name = 'GA4_report', engine = 'xlsxwriter')\n",
        "   # return response\n",
        "   # format_report(request)\n",
        "\n",
        "if __name__== \"__main__\":\n",
        "\n",
        "  \"\"\"poperty=input(\"enter your poperty number         \")\"\"\"\n",
        "  X=input(\"enter your quieres     (u need to inter the matrix right)   \")\n",
        "  extracted_dimintion=extract_dimencions(X)\n",
        "  extracted_matrixs=extract_metrics(X)\n",
        "  data=run_report(429150627,extracted_matrixs,extracted_dimintion)\n",
        " #            a testing sentence\n",
        "\n",
        "#           fitch the totalUsers and the browse\n",
        "\n",
        "\n",
        "#ignore this comments\n",
        "\"\"\"json_object = json.dumps(data, indent=4)\n",
        "\n",
        "# Writing to sample.json\n",
        "with open(\"sample.json\", \"w\") as outfile:\n",
        "\toutfile.write(data)\"\"\"\n",
        "\n",
        "\n",
        "#fitch the totalUsers and the browser\n",
        "#  output_df=run_report(429150627,extracted_matrixs,extracted_dimintion)\n",
        "  #output_df.reset_index().to_excel('GA4_python_output.xlsx', sheet_name = 'GA4_report', engine = 'xlsxwriter')\n",
        "#  output_df.to_csv('GA4_python_output.csv')\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "O1QyeXFVp5I8"
      }
    }
  ]
}